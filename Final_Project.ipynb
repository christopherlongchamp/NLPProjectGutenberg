{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af379f5f-9717-4fa2-903a-b4ba4049e5fa",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "```yaml\n",
    "Course:    DS 5001 \n",
    "Module:    Final Project\n",
    "Author:    Chris Longchamp\n",
    "Date:      2 May 2023\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380a03f-8de9-480d-b4de-62c438771fbe",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4c4358-1c14-47a5-a8b0-5d8cea18285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = \"../DS5001\"\n",
    "local_lib = \"../DS5001/lib\"\n",
    "source_files = f'{data_home}/NLPProjectGutenberg/final-set'\n",
    "data_prefix = 'final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb4bdea-5390-4804-8892-a596e9a44207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "import sys\n",
    "sys.path.append(local_lib)\n",
    "from textparser import TextParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6708974-4a05-4437-bcc9-f2f1442c81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_pats = [\n",
    "    r\"\\*\\*\\*\\s*START OF\",\n",
    "    r\"\\*\\*\\*\\s*END OF\"\n",
    "]\n",
    "\n",
    "# All are 'chap'and 'm'\n",
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "ohco_pat_list = [\n",
    "    (805,   rf\"^\\s*CHAPTER\\s\\d+\\. | INTERLUDE\"),\n",
    "    (4368,  rf\"^\\s*CHAPTER\\s+{roman}$\"),\n",
    "    (64317,  rf\"^\\s*{roman}$\"),\n",
    "    (6695, rf\"^^\\s*CHAPTER\\s+{roman}\"),\n",
    "    (68229, rf\"^[A-Z\\s]+$\"),\n",
    "    (144, rf\"^\\s*CHAPTER\\s+{roman}\"),\n",
    "    (1245, rf\"^\\s*CHAPTER\\s+{roman}\"),\n",
    "    (5670, rf\"^\\s*CHAPTER\\s\"),\n",
    "    (29220, rf\"^[A-Z\\s]+$\"),\n",
    "    (61085, rf\"^\\s*chapter\\s*\\d+\\s*\"),\n",
    "    (63022, rf\"^\\s*Chapter\\s\\d+\"),\n",
    "    (63107, rf\"^[MRS DALLOWAY IN BOND STREET\\s]+$\"),\n",
    "    (64457, rf\"^_([A-Za-z\\s]+)_+$\"),\n",
    "    (67138, rf\"^\\s*CHAPTER\\n\\s*\\d+$\"),\n",
    "    (69683, rf\"^[A-Z\\s]+$\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e4d01c1-8b59-439d-8536-9bee3558cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_list = sorted(glob(f\"{source_files}/*.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc00310-3015-4edd-b1f4-a169a12931c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = []\n",
    "for source_file_path in source_file_list:\n",
    "    book_id = int(source_file_path.split('-')[-1].split('.')[0].replace('pg',''))\n",
    "    book_title = source_file_path.split('\\\\')[-1].split('-')[0].replace('_', ' ')\n",
    "    book_data.append((book_id, source_file_path, book_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3217b8b0-e570-4ac7-9c8a-f3bb3ebd9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB = pd.DataFrame(book_data, columns=['book_id','source_file_path','raw_title'])\\\n",
    "    .set_index('book_id').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac73619-babe-47ed-80aa-b9dcc201326a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d1a2e7-2bee-4092-9589-c885a3ce7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    LIB['author'] = LIB.raw_title.apply(lambda x: ', '.join(x.split()[:2]))\n",
    "    LIB['title'] = LIB.raw_title.apply(lambda x: ' '.join(x.split()[2:]))\n",
    "    LIB = LIB.drop('raw_title', axis=1)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7edc0f4-ebce-40dc-a5f8-56469a0a8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['chap_regex'] = LIB.index.map(pd.Series({x[0]:x[1] for x in ohco_pat_list}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dcbeaa3-e63b-4b6e-bb62-57cd85d00de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>chap_regex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>../DS5001/NLPProjectGutenberg/final-set\\VIRGIN...</td>\n",
       "      <td>VIRGINIA, WOOLF</td>\n",
       "      <td>THE VOYAGE OUT</td>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path           author  \\\n",
       "book_id                                                                       \n",
       "144      ../DS5001/NLPProjectGutenberg/final-set\\VIRGIN...  VIRGINIA, WOOLF   \n",
       "\n",
       "                  title               chap_regex  \n",
       "book_id                                           \n",
       "144      THE VOYAGE OUT  ^\\s*CHAPTER\\s+[IVXLCM]+  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4b85b3c-b619-4aef-9be1-e9b755e39fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_collection(LIB):\n",
    "\n",
    "    clip_pats = [\n",
    "        r\"\\*\\*\\*\\s*START OF\",\n",
    "        r\"\\*\\*\\*\\s*END OF\"\n",
    "    ]\n",
    "\n",
    "    books = []\n",
    "    for book_id in LIB.index:\n",
    "\n",
    "        # Announce\n",
    "        print(\"Tokenizing\", book_id, LIB.loc[book_id].title)\n",
    "\n",
    "        # Define vars\n",
    "        chap_regex = LIB.loc[book_id].chap_regex\n",
    "        ohco_pats = [('chap', chap_regex, 'm')]\n",
    "        src_file_path = LIB.loc[book_id].source_file_path\n",
    "\n",
    "        # Create object\n",
    "        text = TextParser(src_file_path, ohco_pats=ohco_pats, clip_pats=clip_pats, use_nltk=True)\n",
    "\n",
    "        # Define parameters\n",
    "        text.verbose = True\n",
    "        text.strip_hyphens = True\n",
    "        text.strip_whitespace = True\n",
    "\n",
    "        # Parse\n",
    "        text.import_source().parse_tokens();\n",
    "\n",
    "        # Name things\n",
    "        text.TOKENS['book_id'] = book_id\n",
    "        text.TOKENS = text.TOKENS.reset_index().set_index(['book_id'] + text.OHCO)\n",
    "\n",
    "        # Add to list\n",
    "        books.append(text.TOKENS)\n",
    "        \n",
    "    # Combine into a single dataframe\n",
    "    CORPUS = pd.concat(books).sort_index()\n",
    "\n",
    "    # Clean up\n",
    "    del(books)\n",
    "    del(text)\n",
    "        \n",
    "    print(\"Done\")\n",
    "        \n",
    "    return CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eacd40e-ade6-4755-b759-85ef78125ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing 6695 TALES OF THE JAZZ AGE\n",
      "Importing  ../DS5001/NLPProjectGutenberg/final-set\\F.SCOTT_FITZGERALD_TALES_OF_THE_JAZZ_AGE-pg6695.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^^\\s*CHAPTER\\s+[IVXLCM]+\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "CORPUS = tokenize_collection(LIB.iloc[[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09a33fa1-d988-4dd8-8249-2ce3902b5386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">6695</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Jim, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Jim</td>\n",
       "      <td>jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Powell, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Powell</td>\n",
       "      <td>powell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(was, VBD)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>was</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(a, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Jelly, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Jelly</td>\n",
       "      <td>jelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">62</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">24</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>12</th>\n",
       "      <td>(they, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>they</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(made, VBD)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>made</td>\n",
       "      <td>made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(were, VBD)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>were</td>\n",
       "      <td>were</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(as, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>as</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(one., NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>one.</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86910 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pos_tuple  pos token_str  \\\n",
       "book_id chap_id para_num sent_num token_num                                 \n",
       "6695    1       1        0        0             (Jim, NNP)  NNP       Jim   \n",
       "                                  1          (Powell, NNP)  NNP    Powell   \n",
       "                                  2             (was, VBD)  VBD       was   \n",
       "                                  3                (a, DT)   DT         a   \n",
       "                                  4           (Jelly, NNP)  NNP     Jelly   \n",
       "...                                                    ...  ...       ...   \n",
       "        62      24       0        12           (they, PRP)  PRP      they   \n",
       "                                  13           (made, VBD)  VBD      made   \n",
       "                                  14           (were, VBD)  VBD      were   \n",
       "                                  15              (as, IN)   IN        as   \n",
       "                                  16            (one., NN)   NN      one.   \n",
       "\n",
       "                                            term_str  \n",
       "book_id chap_id para_num sent_num token_num           \n",
       "6695    1       1        0        0              jim  \n",
       "                                  1           powell  \n",
       "                                  2              was  \n",
       "                                  3                a  \n",
       "                                  4            jelly  \n",
       "...                                              ...  \n",
       "        62      24       0        12            they  \n",
       "                                  13            made  \n",
       "                                  14            were  \n",
       "                                  15              as  \n",
       "                                  16             one  \n",
       "\n",
       "[86910 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
